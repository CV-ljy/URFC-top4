{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def pro2label(label,pro):\n",
    "    cnt=0\n",
    "    for i in range(pro.shape[0]):\n",
    "        if np.argmax(pro[i,:])==label[i]:\n",
    "            cnt+=1\n",
    "    return cnt/pro.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"VAL/\"\n",
    "files=os.listdir(root)\n",
    "csv=[]\n",
    "npy=[]\n",
    "for file in files:\n",
    "    if file.count(\".csv\")>0:\n",
    "        csv.append(root+file)\n",
    "    elif file==\"RULE\" or file==\"val_files.txt\" or file==\"model123_index\":\n",
    "        continue\n",
    "    else:\n",
    "        subfiles=os.listdir(root+file+\"/\")\n",
    "        for subfile in subfiles:\n",
    "            if subfile.count(\"acc\")>0:\n",
    "                npy.append(root+file+\"/\"+subfile)\n",
    "npy.sort()\n",
    "csv.sort()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels=[]\n",
    "ids=[]\n",
    "f=open(root+\"val_files.txt\")\n",
    "lines=f.readlines()\n",
    "for line in lines:\n",
    "    s=line.split(\"/\")[-1].split(\".txt\")[0].split(\"_\")\n",
    "    true_labels.append(int(s[1]))\n",
    "    ids.append(int(s[0]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single(data):\n",
    "    assert data.shape==(50000,9)\n",
    "    cnt=0\n",
    "    for i in range(50000):\n",
    "        temp=data[i,:]\n",
    "        if np.argmax(temp)+1==true_labels[i]:\n",
    "            cnt+=1\n",
    "    return cnt/50000\n",
    "def csv2npy(file,num=50000):\n",
    "    f=open(file)\n",
    "    return_npy=np.zeros([num,9])\n",
    "    lines=f.readlines()\n",
    "    cnt=0\n",
    "    for line in lines:\n",
    "        s=line.split(\",\")\n",
    "        for k in range(9):\n",
    "            return_npy[cnt,k]=float(s[k])\n",
    "        cnt+=1\n",
    "    f.close()\n",
    "    return return_npy\n",
    "def npy2npy(file,num=50000):\n",
    "    data=np.load(file)\n",
    "    assert data.shape==(num,9)\n",
    "    return data\n",
    "def bn(temp):\n",
    "    shp=temp.shape\n",
    "    MEAN=np.mean(temp,axis=1)\n",
    "    STD=np.std(temp,axis=1)\n",
    "    for i in range(shp[0]):\n",
    "        temp[i,:]=(temp[i,:]-MEAN[i])/(STD[i]+1e-10)\n",
    "    temp0=np.zeros([temp.shape[0],9])\n",
    "    for j in range(temp.shape[0]):\n",
    "        SUM=0.0\n",
    "        for i in range(9):\n",
    "            SUM+=math.exp(float(temp[j,i]))\n",
    "        for i in range(9):\n",
    "            temp0[j,i]=math.exp(float(temp[j,i]))/SUM\n",
    "    return temp0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the acc on the val dataset in 28 CNN models:\n",
      "val acc: 0.6838 VAL/csvO[1_18].csv 0\n",
      "val acc: 0.67364 VAL/csvO[2_18].csv 1\n",
      "val acc: 0.67008 VAL/csvO[3_31].csv 2\n",
      "val acc: 0.69878 VAL/101/VAL_csv_0716_0_best_acc.npy 3\n",
      "val acc: 0.6614 VAL/50_5f/VAL_csv_0716_1_best_acc.npy 4\n",
      "val acc: 0.71152 VAL/50_5f/VAL_csv_0716_2_best_acc.npy 5\n",
      "val acc: 0.7133 VAL/50_5f/VAL_csv_0716_3_best_acc.npy 6\n",
      "val acc: 0.70272 VAL/50_5f/VAL_csv_0716_4_best_acc.npy 7\n",
      "val acc: 0.72154 VAL/50_5f/VAL_csv_0716_5_best_acc.npy 8\n",
      "val acc: 0.6733 VAL/71/VAL_csv_0716_0_best_acc.npy 9\n",
      "val acc: 0.71006 VAL/A/VAL_csv_0716_1_best_acc.npy 10\n",
      "val acc: 0.6971 VAL/A/VAL_csv_0716_2_best_acc.npy 11\n",
      "val acc: 0.7095 VAL/A/VAL_csv_0716_3_best_acc.npy 12\n",
      "val acc: 0.68812 VAL/A/VAL_csv_0716_4_best_acc.npy 13\n",
      "val acc: 0.67054 VAL/A/VAL_csv_0716_5_best_acc.npy 14\n",
      "val acc: 0.67014 VAL/A/VAL_csv_0716_6_best_acc.npy 15\n",
      "val acc: 0.66088 VAL/A/VAL_csv_0716_7_best_acc.npy 16\n",
      "val acc: 0.66436 VAL/A/VAL_csv_0716_8_best_acc.npy 17\n",
      "val acc: 0.70258 VAL/B/VAL_csv_0716_2_best_acc.npy 18\n",
      "val acc: 0.7069 VAL/C/VAL_csv_0716_10_best_acc.npy 19\n",
      "val acc: 0.70774 VAL/C/VAL_csv_0716_1_best_acc.npy 20\n",
      "val acc: 0.67052 VAL/C/VAL_csv_0716_2_best_acc.npy 21\n",
      "val acc: 0.70472 VAL/C/VAL_csv_0716_5_best_acc.npy 22\n",
      "val acc: 0.70628 VAL/C/VAL_csv_0716_6_best_acc.npy 23\n",
      "val acc: 0.67204 VAL/C/VAL_csv_0716_7_best_acc.npy 24\n",
      "val acc: 0.675 VAL/C/VAL_csv_0716_8_best_acc.npy 25\n",
      "val acc: 0.70526 VAL/C/VAL_csv_0716_9_best_acc.npy 26\n",
      "val acc: 0.59964 VAL/squeezenet/VAL_csv_0716_1_best_acc.npy 27\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "model_names=[]\n",
    "id2index={}\n",
    "cnt=0\n",
    "for i in ids:\n",
    "    id2index[i]=cnt\n",
    "    cnt+=1\n",
    "for file in csv:\n",
    "    s=file.split(\"[\")[1].split(\"_\")[0]\n",
    "    temp_id=np.load(root+\"model123_index/name_id\"+str(s)+\".npy\")\n",
    "    temp=np.zeros([50000,9])\n",
    "    temp_npy=csv2npy(file)\n",
    "    cnt=0\n",
    "    for i in temp_id:\n",
    "        index=id2index[i]\n",
    "        temp[index,:]=temp_npy[cnt,:]\n",
    "        cnt+=1\n",
    "    models.append(temp)\n",
    "    model_names.append(file)\n",
    "for file in npy:\n",
    "    models.append(npy2npy(file))\n",
    "    model_names.append(file)\n",
    "cnt=0\n",
    "acc_model=[]\n",
    "print(\"the acc on the val dataset in 28 CNN models:\")\n",
    "for model in models:\n",
    "    acc=single(model)\n",
    "    acc_model.append([acc,model_names[cnt],model])\n",
    "    print(\"val acc:\",acc,model_names[cnt],cnt)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruletxt2num(file):\n",
    "    data=np.zeros([50000,9])\n",
    "    f=open(file)\n",
    "    lines=f.readlines()\n",
    "    cnt=0\n",
    "    for line in lines:\n",
    "        s=line.split(\",\")\n",
    "        for i in range(9):\n",
    "            data[cnt][i]=float(s[i+1])\n",
    "        cnt+=1\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "rule_names=[]\n",
    "temp=os.listdir(root+\"RULE/\")\n",
    "temp.sort()\n",
    "for subpath in temp:\n",
    "    rule_names.append(root+\"RULE/\"+subpath+\"/\")\n",
    "\n",
    "numvalues=[]\n",
    "for rule_name in rule_names:\n",
    "    files=os.listdir(rule_name)\n",
    "    if \"id2num_val.txt\" in files:\n",
    "        temp_num=ruletxt2num(rule_name+\"id2num_val.txt\")\n",
    "        numvalues.append(temp_num)\n",
    "    elif \"id2num_val.npy\" in files:\n",
    "        numvalues.append(npy2npy(rule_name+\"id2num_val.npy\"))\n",
    "    else:\n",
    "        print(\"error!\",rule_name,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the acc on the val dataset in 7 rules and the LGB base model:\n",
      "val acc: 0.7669 VAL/RULE/cxq/ 0\n",
      "val acc: 0.77696 VAL/RULE/cxq2/ 1\n",
      "val acc: 0.6181 VAL/RULE/cxq_lgb/ 2\n",
      "val acc: 0.71704 VAL/RULE/day/ 3\n",
      "val acc: 0.7062 VAL/RULE/hour/ 4\n",
      "val acc: 0.7182 VAL/RULE/lyg_day/ 5\n",
      "val acc: 0.68716 VAL/RULE/lyg_holiday/ 6\n",
      "val acc: 0.68572 VAL/RULE/totaltime/ 7\n"
     ]
    }
   ],
   "source": [
    "acc_rule=[]\n",
    "print(\"the acc on the val dataset in 7 rules and the LGB base model:\")\n",
    "for i,numvalue in enumerate(numvalues):\n",
    "    acc=single(numvalue)\n",
    "    acc_rule.append([acc,rule_names[i],numvalue])\n",
    "    print(\"val acc:\",acc,rule_names[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(data):    #get confusion matrix\n",
    "    assert data.shape==(50000,9)\n",
    "    label_right=np.zeros([9])\n",
    "    label_cnt=np.zeros([9])\n",
    "    cnt=0\n",
    "    for i in range(50000):\n",
    "        temp=data[i,:]\n",
    "        label_cnt[true_labels[i]-1]+=1\n",
    "        if np.argmax(temp)+1==true_labels[i]:\n",
    "            cnt+=1\n",
    "            label_right[true_labels[i]-1]+=1\n",
    "    acc_label=[]\n",
    "    for i in range(9):\n",
    "        acc_label.append(format(label_right[i]/label_cnt[i],\".4f\"))\n",
    "    return acc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=50000\n",
    "model_num=len(acc_model)+len(acc_rule)\n",
    "all_data=np.zeros([model_num,num,9])\n",
    "data=np.zeros([num,model_num*9])\n",
    "labels=np.zeros([num,9])\n",
    "labels_1d=np.zeros([num])\n",
    "for i in range(num):\n",
    "    labels[i,true_labels[i]-1]=1\n",
    "    labels_1d[i]=true_labels[i]\n",
    "cnt=0\n",
    "for _,__,model in acc_model:\n",
    "    if _<0.5:\n",
    "        continue\n",
    "    all_data[cnt,:,:]=bn(model)\n",
    "    cnt+=1\n",
    "for _,__,rule in acc_rule:\n",
    "    # bn\n",
    "    all_data[cnt,:,:]=bn(rule)\n",
    "    cnt+=1\n",
    "for i in range(num):\n",
    "    for j in range(model_num):\n",
    "        data[i,(j*9):((j+1)*9)]=all_data[j,i,:]\n",
    "\n",
    "#######################################\n",
    "VAL_X=data\n",
    "VAL_Y=labels_1d\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VAL/csvO[1_18].csv', 'VAL/csvO[2_18].csv', 'VAL/csvO[3_31].csv', 'VAL/101/VAL_csv_0716_0_best_acc.npy', 'VAL/50_5f/VAL_csv_0716_1_best_acc.npy', 'VAL/50_5f/VAL_csv_0716_2_best_acc.npy', 'VAL/50_5f/VAL_csv_0716_3_best_acc.npy', 'VAL/50_5f/VAL_csv_0716_4_best_acc.npy', 'VAL/50_5f/VAL_csv_0716_5_best_acc.npy', 'VAL/71/VAL_csv_0716_0_best_acc.npy', 'VAL/A/VAL_csv_0716_1_best_acc.npy', 'VAL/A/VAL_csv_0716_2_best_acc.npy', 'VAL/A/VAL_csv_0716_3_best_acc.npy', 'VAL/A/VAL_csv_0716_4_best_acc.npy', 'VAL/A/VAL_csv_0716_5_best_acc.npy', 'VAL/A/VAL_csv_0716_6_best_acc.npy', 'VAL/A/VAL_csv_0716_7_best_acc.npy', 'VAL/A/VAL_csv_0716_8_best_acc.npy', 'VAL/B/VAL_csv_0716_2_best_acc.npy', 'VAL/C/VAL_csv_0716_10_best_acc.npy', 'VAL/C/VAL_csv_0716_1_best_acc.npy', 'VAL/C/VAL_csv_0716_2_best_acc.npy', 'VAL/C/VAL_csv_0716_5_best_acc.npy', 'VAL/C/VAL_csv_0716_6_best_acc.npy', 'VAL/C/VAL_csv_0716_7_best_acc.npy', 'VAL/C/VAL_csv_0716_8_best_acc.npy', 'VAL/C/VAL_csv_0716_9_best_acc.npy', 'VAL/squeezenet/VAL_csv_0716_1_best_acc.npy'] 28 36\n"
     ]
    }
   ],
   "source": [
    "train_names=[]\n",
    "modelname2index={}\n",
    "cnt=0\n",
    "for _,name,_ in acc_model:\n",
    "    if \"/50_5f/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                modelname2index[\"50_5f\"+str(i)]=cnt\n",
    "                cnt+=1\n",
    "    elif \"squeezenet\" in name:\n",
    "        modelname2index[\"squeezenet\"]=cnt\n",
    "        cnt+=1\n",
    "    elif \"/101/\" in name:\n",
    "        modelname2index[\"101\"]=cnt\n",
    "        cnt+=1\n",
    "    elif \"/71/\" in name:\n",
    "        modelname2index[\"71\"]=cnt\n",
    "        cnt+=1\n",
    "    elif \"/A/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                modelname2index[\"A\"+str(i)]=cnt\n",
    "                cnt+=1\n",
    "    elif \"/B/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                modelname2index[\"B\"+str(i)]=cnt\n",
    "                cnt+=1\n",
    "    elif \"/C/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                modelname2index[\"C\"+str(i)]=cnt\n",
    "                cnt+=1\n",
    "    else:\n",
    "        for i in [1,2,3]:\n",
    "            if \"[\"+str(i) in name:\n",
    "                modelname2index[str(i)]=cnt\n",
    "                cnt+=1\n",
    "    train_names.append(name)\n",
    "print(train_names,len(train_names),model_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################测试数据读取\n",
    "root=\"TEST/\"\n",
    "files=os.listdir(root)\n",
    "csv=[]\n",
    "npy=[]\n",
    "for file in files:\n",
    "    if file.count(\".csv\")>0:\n",
    "        csv.append(root+file)\n",
    "    elif \"RULE\" in file:\n",
    "        continue\n",
    "    else:\n",
    "        subfiles=os.listdir(root+file+\"/\")\n",
    "        for subfile in subfiles:\n",
    "            if \"loss\" not in subfile:\n",
    "                npy.append(root+file+\"/\"+subfile)\n",
    "\n",
    "temp=[]\n",
    "temp1=[]\n",
    "for name in npy:\n",
    "    if \"/50_5f/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                temp1.append(name)\n",
    "                temp.append(\"50_5f\"+str(i))\n",
    "    elif \"squeezenet\" in name:\n",
    "        temp1.append(name)\n",
    "        temp.append(\"squeezenet\")\n",
    "    elif \"/101/\" in name:\n",
    "        temp1.append(name)\n",
    "        temp.append(\"101\")\n",
    "    elif \"/71/\" in name:\n",
    "        temp1.append(name)\n",
    "        temp.append(\"71\")\n",
    "    elif \"/A/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                temp1.append(name)\n",
    "                temp.append(\"A\"+str(i))\n",
    "    elif \"/B/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                temp1.append(name)\n",
    "                temp.append(\"B\"+str(i))\n",
    "    elif \"/C/\" in name:\n",
    "        for i in range(11):\n",
    "            if \"_\"+str(i)+\"_\" in name:\n",
    "                temp1.append(name)\n",
    "                temp.append(\"C\"+str(i))\n",
    "    else:\n",
    "        for i in [1,2,3]:\n",
    "            if \"[\"+str(i) in name:\n",
    "                temp1.append(name)\n",
    "                temp.append(str(i))\n",
    "for name in csv:\n",
    "    for i in [1,2,3]:\n",
    "        if \"[\"+str(i) in name:\n",
    "            temp1.append(name)\n",
    "            temp.append(str(i))\n",
    "test_files=[0 for i in range(len(temp))]\n",
    "test_model_name=[]\n",
    "for i,name in enumerate(temp):\n",
    "    test_model_name.append(name)\n",
    "    test_files[modelname2index[name]]=temp1[i]\n",
    "\n",
    "test_model_num=len(test_files)+len(rule_names)\n",
    "models=np.zeros([test_model_num,100000,9])\n",
    "cnt=0\n",
    "for file in test_files:\n",
    "    if \".csv\" in file:\n",
    "        npy=csv2npy(file,100000)\n",
    "    else:\n",
    "        npy=npy2npy(file,100000)\n",
    "    models[cnt,:,:]=bn(npy)\n",
    "    cnt+=1\n",
    "for rule_name in rule_names:\n",
    "    s=rule_name.split(\"/\")[-2]\n",
    "    files=os.listdir(root+\"RULE/\"+s+\"/\")\n",
    "    npy=npy2npy(root+\"RULE/\"+s+\"/\"+files[0],100000)\n",
    "    models[cnt,:,:]=bn(npy)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=100000\n",
    "model_num=test_model_num\n",
    "data=np.zeros([num,model_num*9])\n",
    "for i in range(num):\n",
    "    for j in range(model_num):\n",
    "        data[i,(j*9):((j+1)*9)]=models[j,i,:]\n",
    "\n",
    "if not os.path.exists(\"SUBMISSION\"):\n",
    "    os.makedirs(\"SUBMISSION\")\n",
    "###############################\n",
    "TEST_X=data\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 324) (50000,) (100000, 324)\n"
     ]
    }
   ],
   "source": [
    "#36个模型的输出已经全部读取并归一化\n",
    "#VAL_X 的维度为[50000,36*9],二维矩阵，36个模型在验证集的输出拼接而成\n",
    "#VAL_Y 的维度为[50000],一维向量，验证集样本的类别标注，数值从1到9\n",
    "#TEST_X 的维度为[100000,36*9],二维矩阵，36个模型在测试集的输出拼接而成\n",
    "#接下来只需利用VAL_X、VAL_Y、TEST_X 三个变量进行集成学习训练lgb即可\n",
    "print(VAL_X.shape,VAL_Y.shape,TEST_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain's multi_error: 0.138175\tvalid's multi_error: 0.1719\n",
      "[100]\ttrain's multi_error: 0.11855\tvalid's multi_error: 0.1538\n",
      "[150]\ttrain's multi_error: 0.113725\tvalid's multi_error: 0.1518\n",
      "[200]\ttrain's multi_error: 0.110575\tvalid's multi_error: 0.1515\n",
      "[250]\ttrain's multi_error: 0.10865\tvalid's multi_error: 0.1504\n",
      "[300]\ttrain's multi_error: 0.106125\tvalid's multi_error: 0.1501\n",
      "[350]\ttrain's multi_error: 0.103375\tvalid's multi_error: 0.1502\n",
      "[400]\ttrain's multi_error: 0.101125\tvalid's multi_error: 0.1496\n",
      "[450]\ttrain's multi_error: 0.097925\tvalid's multi_error: 0.1497\n",
      "[500]\ttrain's multi_error: 0.095575\tvalid's multi_error: 0.1494\n",
      "[550]\ttrain's multi_error: 0.0937\tvalid's multi_error: 0.1492\n",
      "[600]\ttrain's multi_error: 0.09095\tvalid's multi_error: 0.1482\n",
      "[650]\ttrain's multi_error: 0.087875\tvalid's multi_error: 0.1476\n",
      "[700]\ttrain's multi_error: 0.084925\tvalid's multi_error: 0.1477\n",
      "[750]\ttrain's multi_error: 0.081425\tvalid's multi_error: 0.147\n",
      "[800]\ttrain's multi_error: 0.07905\tvalid's multi_error: 0.1465\n",
      "[850]\ttrain's multi_error: 0.076325\tvalid's multi_error: 0.1472\n",
      "[900]\ttrain's multi_error: 0.074125\tvalid's multi_error: 0.1474\n",
      "[950]\ttrain's multi_error: 0.071525\tvalid's multi_error: 0.1458\n",
      "[1000]\ttrain's multi_error: 0.069025\tvalid's multi_error: 0.1452\n",
      "[1050]\ttrain's multi_error: 0.06645\tvalid's multi_error: 0.1447\n",
      "[1100]\ttrain's multi_error: 0.064275\tvalid's multi_error: 0.1451\n",
      "[1150]\ttrain's multi_error: 0.062075\tvalid's multi_error: 0.1453\n",
      "[1200]\ttrain's multi_error: 0.059775\tvalid's multi_error: 0.1455\n",
      "[1250]\ttrain's multi_error: 0.057275\tvalid's multi_error: 0.1454\n",
      "[1300]\ttrain's multi_error: 0.0557\tvalid's multi_error: 0.145\n",
      "[1350]\ttrain's multi_error: 0.05345\tvalid's multi_error: 0.1453\n",
      "[1400]\ttrain's multi_error: 0.051525\tvalid's multi_error: 0.1452\n",
      "[1450]\ttrain's multi_error: 0.0493\tvalid's multi_error: 0.1446\n",
      "[1500]\ttrain's multi_error: 0.047575\tvalid's multi_error: 0.1438\n",
      "[1550]\ttrain's multi_error: 0.045925\tvalid's multi_error: 0.1436\n",
      "[1600]\ttrain's multi_error: 0.04385\tvalid's multi_error: 0.1434\n",
      "[1650]\ttrain's multi_error: 0.041775\tvalid's multi_error: 0.1438\n",
      "[1700]\ttrain's multi_error: 0.04005\tvalid's multi_error: 0.1434\n",
      "[1750]\ttrain's multi_error: 0.038025\tvalid's multi_error: 0.1437\n",
      "[1800]\ttrain's multi_error: 0.035975\tvalid's multi_error: 0.1434\n",
      "[1850]\ttrain's multi_error: 0.033975\tvalid's multi_error: 0.1434\n",
      "[1900]\ttrain's multi_error: 0.0319\tvalid's multi_error: 0.1435\n",
      "[1950]\ttrain's multi_error: 0.0303\tvalid's multi_error: 0.1432\n",
      "[2000]\ttrain's multi_error: 0.028525\tvalid's multi_error: 0.143\n",
      "[2050]\ttrain's multi_error: 0.026675\tvalid's multi_error: 0.143\n",
      "[2100]\ttrain's multi_error: 0.025125\tvalid's multi_error: 0.1429\n",
      "[2150]\ttrain's multi_error: 0.02385\tvalid's multi_error: 0.1425\n",
      "[2200]\ttrain's multi_error: 0.022775\tvalid's multi_error: 0.1427\n",
      "[2250]\ttrain's multi_error: 0.02165\tvalid's multi_error: 0.1429\n",
      "[2300]\ttrain's multi_error: 0.0204\tvalid's multi_error: 0.1423\n",
      "[2350]\ttrain's multi_error: 0.01885\tvalid's multi_error: 0.1428\n",
      "[2400]\ttrain's multi_error: 0.0177\tvalid's multi_error: 0.1429\n",
      "[2450]\ttrain's multi_error: 0.016275\tvalid's multi_error: 0.1427\n",
      "[2500]\ttrain's multi_error: 0.015125\tvalid's multi_error: 0.1426\n",
      "[2550]\ttrain's multi_error: 0.013725\tvalid's multi_error: 0.1426\n",
      "[2600]\ttrain's multi_error: 0.0127\tvalid's multi_error: 0.1424\n",
      "[2650]\ttrain's multi_error: 0.01185\tvalid's multi_error: 0.1421\n",
      "[2700]\ttrain's multi_error: 0.01075\tvalid's multi_error: 0.142\n",
      "[2750]\ttrain's multi_error: 0.009775\tvalid's multi_error: 0.1422\n",
      "[2800]\ttrain's multi_error: 0.009125\tvalid's multi_error: 0.142\n",
      "[2850]\ttrain's multi_error: 0.0084\tvalid's multi_error: 0.142\n",
      "[2900]\ttrain's multi_error: 0.0078\tvalid's multi_error: 0.1422\n",
      "[2950]\ttrain's multi_error: 0.007025\tvalid's multi_error: 0.1421\n",
      "[3000]\ttrain's multi_error: 0.00655\tvalid's multi_error: 0.1419\n",
      "[3050]\ttrain's multi_error: 0.00605\tvalid's multi_error: 0.1418\n",
      "[3100]\ttrain's multi_error: 0.005575\tvalid's multi_error: 0.1417\n",
      "[3150]\ttrain's multi_error: 0.005125\tvalid's multi_error: 0.1415\n",
      "[3200]\ttrain's multi_error: 0.00465\tvalid's multi_error: 0.1415\n",
      "[3250]\ttrain's multi_error: 0.004125\tvalid's multi_error: 0.1414\n",
      "train_acc： 0.995875 val_acc： 0.8586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "params = {\n",
    "'boosting_type': 'dart',\n",
    "'objective': 'multiclassova',  \n",
    "'num_class': 9,  \n",
    "'metric': 'multi_error', \n",
    "'num_leaves': 63,\n",
    "'learning_rate': 0.01,\n",
    "'feature_fraction': 0.9,\n",
    "'bagging_fraction': 0.9,\n",
    "'bagging_seed':0,\n",
    "'bagging_freq': 1,\n",
    "'verbose': -1,\n",
    "'reg_alpha':1,\n",
    "'reg_lambda':2,\n",
    "'lambda_l1': 0,\n",
    "'lambda_l2': 1,\n",
    "'num_threads': 16,\n",
    "'drop_rate':0.95,\n",
    "}\n",
    "############################################################################ 5万验证集拿出4万训练并留1万数据验证（为了找出最佳的训练轮数）\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(VAL_X, VAL_Y-1, test_size=0.2, random_state=2019)\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=3250,    #3250轮是试验得出，val loss不再下降\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                #early_stopping_rounds=300,\n",
    "                verbose_eval=50,\n",
    "                )\n",
    "train_pro = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
    "val_pro = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "print ('train_acc：',pro2label(y_train,train_pro),'val_acc：',pro2label(y_valid,val_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's multi_error: 0.1232\n",
      "[200]\ttrain's multi_error: 0.11638\n",
      "[300]\ttrain's multi_error: 0.11238\n",
      "[400]\ttrain's multi_error: 0.10748\n",
      "[500]\ttrain's multi_error: 0.10236\n",
      "[600]\ttrain's multi_error: 0.09754\n",
      "[700]\ttrain's multi_error: 0.09242\n",
      "[800]\ttrain's multi_error: 0.08686\n",
      "[900]\ttrain's multi_error: 0.08208\n",
      "[1000]\ttrain's multi_error: 0.07728\n",
      "[1100]\ttrain's multi_error: 0.07302\n",
      "[1200]\ttrain's multi_error: 0.06902\n",
      "[1300]\ttrain's multi_error: 0.06558\n",
      "[1400]\ttrain's multi_error: 0.06152\n",
      "[1500]\ttrain's multi_error: 0.05774\n",
      "[1600]\ttrain's multi_error: 0.05372\n",
      "[1700]\ttrain's multi_error: 0.05054\n",
      "[1800]\ttrain's multi_error: 0.0472\n",
      "[1900]\ttrain's multi_error: 0.04344\n",
      "[2000]\ttrain's multi_error: 0.03976\n",
      "[2100]\ttrain's multi_error: 0.03642\n",
      "[2200]\ttrain's multi_error: 0.03328\n",
      "[2300]\ttrain's multi_error: 0.02986\n",
      "[2400]\ttrain's multi_error: 0.02708\n",
      "[2500]\ttrain's multi_error: 0.02392\n",
      "[2600]\ttrain's multi_error: 0.02128\n",
      "[2700]\ttrain's multi_error: 0.01942\n",
      "[2800]\ttrain's multi_error: 0.01742\n",
      "[2900]\ttrain's multi_error: 0.01552\n",
      "[3000]\ttrain's multi_error: 0.01416\n",
      "[3100]\ttrain's multi_error: 0.01272\n",
      "[3200]\ttrain's multi_error: 0.01112\n",
      "[3300]\ttrain's multi_error: 0.0098\n"
     ]
    }
   ],
   "source": [
    "############################################################################ 5万验证集全部用于训练\n",
    "lgb_train = lgb.Dataset(VAL_X, VAL_Y-1)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=3250+100,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=100,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################测试并生成SUBMISSION\n",
    "f=open(\"SUBMISSION/lgb_dart095_8586_2ruleall_cxq2ruleall.txt\",\"w\")\n",
    "ans=gbm.predict(TEST_X, num_iteration=3350)\n",
    "for i in range(100000):\n",
    "    f.write(str(i).zfill(6)+\"\\t\"+str(int(np.argmax(ans[i])+1)).zfill(3)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f57255df6d8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.save_model(\"lgb_dart095_8586.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
